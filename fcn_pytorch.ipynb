{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import trange\n",
    "from tensorboardX import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import RetinaMNIST\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/matthijs/.medmnist/retinamnist.npz\n"
     ]
    }
   ],
   "source": [
    "num_samples = 16\n",
    "info = INFO[\"retinamnist\"]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=True, as_rgb=True)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=num_samples, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f07e7412e50>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input, label = next(iter(train_loader))\n",
    "print(input[7].shape)\n",
    "plt.imshow(np.swapaxes(input[7],0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94707/1610795133.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def train(model, criterion, optimizer, device, writer, inputs, targets):\n",
    "    total_loss = []\n",
    "    global iteration\n",
    "\n",
    "    model.train()\n",
    "    g_layer1 = []\n",
    "    g_layer2 = []\n",
    "    # for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    #     if batch_idx > num_batches: # for now, let's only look at two batches\n",
    "    #         break\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs.to(device))\n",
    "\n",
    "    targets = torch.squeeze(targets, 1).long().to(device)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    total_loss.append(loss.item())\n",
    "    writer.add_scalar('train_loss_logs', loss.item(), iteration)\n",
    "    iteration += 1\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    G_layer1 = model.fc1.weight.grad\n",
    "    G_layer2 = model.fc2.weight.grad\n",
    "    G_layers = [G_layer1, G_layer2]\n",
    "        # print(model.fc2.weight.grad[0])\n",
    "    #     if batch_idx==0:\n",
    "    #         G_layer1 = model.fc1.weight.grad\n",
    "    #         G_layer2 = model.fc2.weight.grad\n",
    "    #     else:\n",
    "    #         G_layer1 += model.fc1.weight.grad\n",
    "    #         G_layer2 += model.fc2.weight.grad\n",
    "\n",
    "    # G_layer1 /= num_batches\n",
    "    # G_layer2 /= num_batches\n",
    "    epoch_loss = sum(total_loss)/len(total_loss)\n",
    "    return epoch_loss, G_layers\n",
    "\n",
    "\n",
    "# Define model and optimizer\n",
    "model = MyModel(3*28*28)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "inputs, targets = next(iter(train_loader))\n",
    "epoch_loss, G_layers = train(model, criterion, optimizer, \"cpu\", writer, inputs, targets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_values(arr: np.ndarray) -> np.ndarray:\n",
    "    unique_vals, counts = np.unique(arr, return_counts=True)\n",
    "    dup_vals = unique_vals[(counts>1)*(~np.isinf(unique_vals))]\n",
    "    idcs = np.argwhere(np.array([(val  in dup_vals) for val in arr]))\n",
    "    return idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disjoint index group [[ 22]\n",
      " [ 31]\n",
      " [ 43]\n",
      " [136]\n",
      " [216]\n",
      " [230]\n",
      " [237]\n",
      " [242]\n",
      " [285]\n",
      " [306]\n",
      " [313]\n",
      " [377]\n",
      " [382]\n",
      " [426]\n",
      " [472]\n",
      " [506]]\n",
      "[[-2.56178761  0.62324335  0.59707318  0.64772787  0.66666667]\n",
      " [-2.41025544  0.62909375  0.54451473  0.6094141   0.66666667]\n",
      " [-2.55420892  0.66666667  0.57703614  0.64581164  0.66469445]\n",
      " [-2.55420909  0.66666667  0.57703617  0.64581175  0.66469449]\n",
      " [-2.56178751  0.62324332  0.57874827  0.64772786  0.66666667]\n",
      " [-2.55420891  0.66666667  0.57703617  0.64581164  0.66469444]\n",
      " [-2.55420884  0.66666667  0.57703613  0.64581166  0.66469443]\n",
      " [-2.55420906  0.66666667  0.57703618  0.63101909  0.66469447]\n",
      " [-2.55420887  0.66666667  0.57703611  0.63101904  0.66469445]\n",
      " [-2.5542089   0.66666667  0.59530682  0.64581165  0.66469443]\n",
      " [-2.55420891  0.66666667  0.57703612  0.6458117   0.6646944 ]\n",
      " [-2.55420903  0.66666667  0.57703611  0.64581166  0.66469442]\n",
      " [-2.5617876   0.62324335  0.57874828  0.6328914   0.66666667]\n",
      " [-2.41025543  0.62909371  0.54451475  0.60941412  0.66666667]\n",
      " [-2.56178757  0.62324333  0.59707316  0.63289136  0.66666667]\n",
      " [-2.55420923  0.66666667  0.57703621  0.64581171  0.66469447]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthijs/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:838: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self.reciprocal() * other\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "def exact_label_reconstruction(loss_vector_ratio):\n",
    "    if np.sum(loss_vector_ratio<0)>0: # The bigger than sign, I am not sure about\n",
    "        return np.argmin(loss_vector_ratio) # I am not sure about this either\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#take batch 0 and epoch 0 \n",
    "def determine_g(GH, output_size=5, num_samples=16):\n",
    "    G1 = GH[0]\n",
    "    G = np.zeros((output_size, G1.shape[0]))\n",
    "    r = np.zeros((output_size, G1.shape[0]))\n",
    "\n",
    "    for c in range(output_size):\n",
    "        G[c] = GH[c]\n",
    "        r[c] = np.round(G[c]/G1,9)\n",
    "\n",
    "    r_2 = r[1]\n",
    "    exans = False\n",
    "    indices = find_duplicate_values(r_2)\n",
    "\n",
    "\n",
    "    if len(indices)>0:\n",
    "        print(\"disjoint index group\", indices)\n",
    "        exans = True\n",
    "\n",
    "    if exans:\n",
    "        ratio_vector = np.zeros((output_size, num_samples))\n",
    "        for c in range(output_size):\n",
    "            for m in range(num_samples):\n",
    "                j = choice(indices)\n",
    "                ratio_vector[c][m] = r[c][j]\n",
    "\n",
    "        g1 = np.zeros((num_samples))\n",
    "        g = np.zeros((num_samples, output_size))\n",
    "        for m in range(num_samples):\n",
    "            Ym = exact_label_reconstruction(ratio_vector[:, m])\n",
    "            delta_m = 1/np.min(ratio_vector[:, m]) # no idea if this is correct, also, not using Ym now\n",
    "            g1[m] = 2 * delta_m/3\n",
    "            g[m] = ratio_vector[:, m] * g1[m]\n",
    "        return indices, g\n",
    "\n",
    "    else:\n",
    "        print(\"no exans\")\n",
    "        return None\n",
    "\n",
    "disjoint_index_groups, g = determine_g(G_layers[1])\n",
    "print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "tensor([[ True, False, False,  ...,  True,  True, False]])\n",
      "tensor([[False, False, False,  ...,  True,  True,  True]])\n",
      "[-1.20822506e-05  1.00460811e-05  9.09071605e-06  1.51124823e-05\n",
      "  8.59964566e-05  0.00000000e+00 -2.70893139e-07  3.86895699e-05\n",
      " -4.07992848e-05  1.93120970e-04  2.05855278e-04 -5.61081433e-05\n",
      "  0.00000000e+00  7.15086353e-05 -5.46470925e-04  0.00000000e+00\n",
      "  2.80650129e-04 -7.41133554e-05  0.00000000e+00  1.69093313e-04\n",
      " -1.22721440e-05 -5.05999815e-05  3.26250665e-06  2.28797080e-06\n",
      "  2.05245669e-05 -4.79785604e-06  0.00000000e+00 -8.27146505e-06\n",
      " -1.84941018e-05 -3.72076943e-06  0.00000000e+00  0.00000000e+00\n",
      "  1.52278844e-05  0.00000000e+00  1.07166728e-04  0.00000000e+00\n",
      "  7.36386573e-05 -3.87737382e-04 -4.23048332e-04  0.00000000e+00\n",
      " -9.95488022e-04  2.76924220e-05 -1.18876365e-03 -2.82876772e-05\n",
      "  2.60130473e-05  2.86237100e-05 -1.55917151e-04 -2.88290466e-04\n",
      "  0.00000000e+00 -4.10469365e-05  3.14602476e-05 -1.30469280e-05\n",
      " -1.18209277e-06  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  1.08930599e-05 -8.59142403e-07 -1.86976649e-05  7.82143761e-05\n",
      "  1.29009068e-05  2.90485536e-06  0.00000000e+00  4.27246676e-04\n",
      "  1.87417376e-04 -3.73089533e-05  0.00000000e+00 -8.78035207e-04\n",
      " -1.72279862e-04 -2.32690611e-04 -8.14069237e-04 -3.81201273e-04\n",
      " -7.20917946e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -1.34760936e-04 -1.21810017e-05  1.06626496e-04 -6.35207653e-06\n",
      " -5.46083413e-07  0.00000000e+00  0.00000000e+00 -1.15352732e-05\n",
      " -8.39176664e-06  6.61331069e-05  4.52456443e-05 -1.74019297e-05\n",
      "  0.00000000e+00 -1.24366183e-04  0.00000000e+00  0.00000000e+00\n",
      " -3.77503893e-04  0.00000000e+00 -7.41371769e-05 -8.85863046e-05\n",
      "  5.73781494e-04  0.00000000e+00 -1.25495414e-03 -9.07568086e-04\n",
      " -4.07338666e-05 -8.26815303e-05 -4.43458790e-04 -2.75685161e-04\n",
      " -5.81601307e-05  1.10429688e-03  3.79910234e-05  1.61764401e-04\n",
      "  1.45400581e-05  0.00000000e+00  4.73615501e-06  0.00000000e+00\n",
      "  7.28728355e-06  3.08453127e-05 -2.16988228e-05  9.61232799e-05\n",
      "  0.00000000e+00  0.00000000e+00 -7.61822230e-05  0.00000000e+00\n",
      "  1.00978755e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  9.39905469e-04  0.00000000e+00 -4.18480020e-04\n",
      " -1.09515304e-03  0.00000000e+00  3.17820522e-04 -4.68079874e-04\n",
      " -9.64154548e-04  9.32572177e-04 -3.19097540e-04  0.00000000e+00\n",
      "  8.54002155e-06  0.00000000e+00 -2.03108248e-05  6.65947955e-05\n",
      "  0.00000000e+00  9.89190767e-07  5.22535302e-05  3.58955498e-04\n",
      "  4.14757698e-04  1.51233529e-04 -1.01695972e-04  7.80216142e-05\n",
      "  0.00000000e+00  1.55181007e-03  0.00000000e+00  0.00000000e+00\n",
      " -4.24411381e-04  2.53117806e-03 -1.41022447e-03  0.00000000e+00\n",
      "  1.25770504e-03  0.00000000e+00  1.31750817e-03  8.35318991e-04\n",
      "  5.48242067e-04  4.31543885e-04 -5.81884175e-04  1.97321730e-04\n",
      " -1.91723084e-04 -2.25512722e-05  6.03186936e-06  3.39224716e-05\n",
      "  4.95573513e-05  4.82485484e-05 -2.09282618e-04 -2.86514725e-04\n",
      "  0.00000000e+00  1.91990202e-05 -3.64587380e-04 -2.31695478e-03\n",
      " -2.26981516e-04  0.00000000e+00 -7.02555117e-05  0.00000000e+00\n",
      "  8.40385212e-04 -4.41321055e-04 -3.72865936e-04 -2.81146895e-05\n",
      "  0.00000000e+00  2.27378318e-04  3.41998151e-04  0.00000000e+00\n",
      "  0.00000000e+00 -1.01240759e-03  8.27726035e-04 -1.73458306e-04\n",
      " -4.08688153e-04  0.00000000e+00  0.00000000e+00  5.05041207e-05\n",
      " -4.15354843e-05  3.97562690e-04  0.00000000e+00 -1.87742291e-04\n",
      " -1.26355357e-04  1.54228369e-03  7.43422832e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -7.30085685e-06  2.65669427e-04\n",
      "  5.14165557e-04  1.50574406e-03 -1.89066865e-03  3.92962771e-04\n",
      "  9.37301302e-05  0.00000000e+00 -2.39068642e-03  1.20995787e-03\n",
      " -5.98407223e-06  0.00000000e+00  1.52914354e-03  1.54856907e-03\n",
      "  8.48327065e-04 -7.14844151e-04 -1.93061671e-04  9.88757711e-06\n",
      "  0.00000000e+00  5.51164325e-04 -1.35259368e-04  7.14453272e-05\n",
      " -7.37094088e-04  4.66825382e-04  8.89208968e-05 -3.87797161e-04\n",
      "  0.00000000e+00 -3.89281668e-05  0.00000000e+00  0.00000000e+00\n",
      "  2.89841485e-03 -2.81664543e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -2.45810021e-04 -3.72061113e-05\n",
      "  5.81406464e-04 -1.40612235e-03  0.00000000e+00 -6.24878856e-04\n",
      " -3.23878659e-04 -1.88984603e-04  0.00000000e+00  3.97302829e-05\n",
      "  1.99899951e-04  2.06958342e-04  0.00000000e+00 -7.93595915e-04\n",
      "  0.00000000e+00  0.00000000e+00  2.44288496e-03  1.71440840e-03\n",
      " -6.86472282e-04  0.00000000e+00  2.26385077e-04 -3.06879578e-04\n",
      " -6.66707056e-04  7.54521578e-04  0.00000000e+00  4.02573787e-05\n",
      " -1.09468959e-03  0.00000000e+00 -4.36835660e-04  1.28805428e-03\n",
      "  2.95379665e-04 -3.45701701e-04 -7.54033899e-05  1.97240981e-04\n",
      "  1.42175588e-03 -8.56314262e-04 -6.69725569e-06  2.95907143e-04\n",
      "  3.30512921e-05  2.95375648e-05 -4.48127394e-04 -1.83416577e-03\n",
      "  9.38510930e-04 -1.09894725e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -1.02442421e-03 -4.38133749e-04  0.00000000e+00\n",
      " -1.94942812e-04 -2.31017388e-04 -2.50907498e-03  3.93518072e-04\n",
      " -8.05849093e-04 -1.64010422e-03 -2.35146610e-04  9.40436439e-04\n",
      "  1.68227742e-03  3.22199921e-04  1.91632542e-03  0.00000000e+00\n",
      " -1.07481924e-03 -1.35645072e-03  1.48424006e-05  1.83773562e-04\n",
      "  6.52928546e-04  9.64506413e-04 -1.59170560e-03  0.00000000e+00\n",
      "  2.53659760e-04 -8.75072656e-05  2.27434328e-04  8.94900077e-05\n",
      "  2.16008816e-03 -4.03182901e-04  1.08005828e-03  0.00000000e+00\n",
      "  0.00000000e+00  8.74235266e-05  1.51572473e-04 -1.72962248e-03\n",
      "  0.00000000e+00  0.00000000e+00  9.66268766e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -6.65767526e-04  7.34247305e-06\n",
      "  0.00000000e+00  6.64224572e-05  5.03708259e-04  0.00000000e+00\n",
      "  1.77405105e-04  0.00000000e+00  7.49994724e-05  0.00000000e+00\n",
      " -5.34382089e-05  4.14525159e-04  7.85766810e-04  0.00000000e+00\n",
      " -2.05905730e-04  8.46738287e-04 -1.25756674e-03  0.00000000e+00\n",
      "  2.57156818e-04 -9.02463973e-04 -1.70473286e-04 -5.97066886e-04\n",
      " -7.70950166e-04  1.81416108e-03 -5.13730862e-04  1.04899856e-03\n",
      "  7.55175948e-04 -7.07575993e-04 -3.12427030e-04  0.00000000e+00\n",
      "  0.00000000e+00  1.92811363e-04  0.00000000e+00  4.28385738e-06\n",
      "  9.83110021e-06  1.47175952e-03  1.59807247e-03  0.00000000e+00\n",
      " -7.67596532e-04  0.00000000e+00 -1.80003059e-03 -6.46144967e-04\n",
      " -2.55287462e-03  0.00000000e+00  0.00000000e+00  4.68342332e-05\n",
      " -8.25051975e-04  1.50345921e-04  4.19898890e-04  1.42986071e-03\n",
      " -1.04665954e-03  2.20400910e-03  7.84632211e-05  3.08152928e-04\n",
      "  3.32148978e-04  1.10765232e-03 -6.78121214e-05 -1.66089251e-03\n",
      "  0.00000000e+00 -1.21946396e-04 -9.80192446e-04 -1.21388433e-03\n",
      "  8.53502133e-04  3.08042741e-04 -1.45931647e-03 -5.68752410e-04\n",
      "  0.00000000e+00  1.15617784e-03  2.29820632e-03 -7.95629749e-04\n",
      "  1.83074415e-04  8.07563774e-04  3.08155286e-04  0.00000000e+00\n",
      " -9.23176936e-04 -1.84447781e-04  0.00000000e+00 -7.83108233e-04\n",
      "  8.14931409e-04  0.00000000e+00  0.00000000e+00 -2.29541142e-03\n",
      "  1.41650741e-03 -7.67242727e-06 -1.26018503e-03 -2.08290480e-03\n",
      "  0.00000000e+00  0.00000000e+00  4.32775778e-05 -9.12657066e-04\n",
      "  0.00000000e+00  0.00000000e+00  1.50594686e-04  0.00000000e+00\n",
      "  1.80071918e-03  7.79737966e-05 -9.03767650e-05  9.60511563e-04\n",
      " -4.86327248e-04  1.54549594e-03  1.76196278e-03 -5.80225547e-04\n",
      "  0.00000000e+00  1.58770452e-03  0.00000000e+00 -6.52701012e-04\n",
      " -1.57884602e-03 -2.08382611e-03  0.00000000e+00  3.48851492e-04\n",
      "  0.00000000e+00  1.06050156e-03  2.35354601e-04 -1.37017388e-03\n",
      " -1.51776522e-03  0.00000000e+00  0.00000000e+00 -3.10827920e-04\n",
      "  9.90834178e-06 -7.98432447e-05  0.00000000e+00  6.66318461e-04\n",
      "  0.00000000e+00 -2.06563319e-03 -6.18033955e-05  8.79019033e-04\n",
      "  0.00000000e+00 -2.45708576e-03  0.00000000e+00 -6.90609741e-04\n",
      "  0.00000000e+00 -1.02580525e-04 -1.19035796e-03  0.00000000e+00\n",
      "  0.00000000e+00 -5.22961724e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  4.27493396e-05  0.00000000e+00  1.89340994e-04\n",
      " -4.79406648e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      " -1.58356808e-04 -8.09636549e-04 -5.21114562e-04  0.00000000e+00\n",
      "  3.72133742e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -2.39591696e-03  8.34057573e-04 -1.77928200e-03\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  1.03585003e-03\n",
      " -1.39855826e-03  0.00000000e+00  1.37979325e-04 -3.00114276e-04\n",
      "  9.16524659e-05  0.00000000e+00 -1.18245301e-03  0.00000000e+00\n",
      "  8.19173933e-04  0.00000000e+00  0.00000000e+00  2.06039491e-04\n",
      "  3.20560721e-05 -1.90739098e-04 -3.20379258e-05  2.86435043e-05\n",
      "  0.00000000e+00 -9.51736438e-05  0.00000000e+00 -1.30875455e-03]\n"
     ]
    }
   ],
   "source": [
    "def determine_activation_pattern(G, IH, g, num_samples=16):\n",
    "    I_cur = IH\n",
    "    # D = ?\n",
    "    for i in reversed(range(len(G)-1)):\n",
    "        for m in range(num_samples):\n",
    "            j = choice(I_cur)\n",
    "            if G[i][j]!=0:\n",
    "                D = np.diag(G[i][j]) # needs to be D[i][m] but for now, let's just do it for one sample\n",
    "            # also how come we select a random j, whiy dont we use all?\n",
    "            # and why only nonzero values?\n",
    "\n",
    "determine_activation_pattern(G_layers, disjoint_index_groups, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
