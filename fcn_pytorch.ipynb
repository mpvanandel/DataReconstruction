{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import trange\n",
    "from tensorboardX import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import RetinaMNIST\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/matthijs/.medmnist/retinamnist.npz\n"
     ]
    }
   ],
   "source": [
    "num_samples = 8\n",
    "info = INFO[\"retinamnist\"]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=True, as_rgb=True)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=num_samples, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe52c0f13a0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input, label = next(iter(train_loader))\n",
    "print(input[7].shape)\n",
    "plt.imshow(np.swapaxes(input[7],0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6278/2726593962.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def train(model, criterion, optimizer, device, writer, inputs, targets):\n",
    "    total_loss = []\n",
    "    global iteration\n",
    "\n",
    "    model.train()\n",
    "    # for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    #     if batch_idx > num_batches: # for now, let's only look at two batches\n",
    "    #         break\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs.to(device))\n",
    "\n",
    "    targets = torch.squeeze(targets, 1).long().to(device)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    total_loss.append(loss.item())\n",
    "    writer.add_scalar('train_loss_logs', loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    G_layer1 = model.fc1.weight.grad\n",
    "    G_layer2 = model.fc2.weight.grad\n",
    "    G_layers = [G_layer1, G_layer2]\n",
    "        # print(model.fc2.weight.grad[0])\n",
    "    #     if batch_idx==0:\n",
    "    #         G_layer1 = model.fc1.weight.grad\n",
    "    #         G_layer2 = model.fc2.weight.grad\n",
    "    #     else:\n",
    "    #         G_layer1 += model.fc1.weight.grad\n",
    "    #         G_layer2 += model.fc2.weight.grad\n",
    "\n",
    "    # G_layer1 /= num_batches\n",
    "    # G_layer2 /= num_batches\n",
    "    epoch_loss = sum(total_loss)/len(total_loss)\n",
    "    return epoch_loss, G_layers\n",
    "\n",
    "\n",
    "# Define model and optimizer\n",
    "model = MyModel(3*28*28)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "\n",
    "inputs, targets = next(iter(train_loader))\n",
    "epoch_loss, G_layers = train(model, criterion, optimizer, \"cpu\", writer, inputs, targets)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disjoint index group {'m_0': array([210, 483]), 'm_1': array([231, 255]), 'm_2': array([205, 335]), 'm_3': array([ 58, 113, 345, 396]), 'm_4': array([168, 370, 445, 465]), 'm_5': array([  0,  53, 204]), 'm_6': array([203, 364]), 'm_7': array([ 75, 457]), 'm_8': array([314, 489]), 'm_9': array([169, 197])}\n",
      "[[-0.17318639  0.66666667 -0.15881026 -0.17172424 -0.16294578]\n",
      " [-0.17318639  0.66666667 -0.15881026 -0.17172423 -0.16294578]\n",
      " [-0.1731864   0.66666667 -0.15881026 -0.17172425 -0.1629458 ]\n",
      " [-2.52341946  0.66666667  0.58213265  0.66150456  0.61311554]\n",
      " [-2.52341956  0.66666667  0.58213269  0.66150453  0.61311559]\n",
      " [-2.5234195   0.66666667  0.58213269  0.66150456  0.61311559]\n",
      " [-2.52341968  0.66666667  0.58213269  0.66150456  0.61311556]\n",
      " [-2.55684977  0.63188622  0.61588661  0.66666667  0.64241058]\n",
      " [-0.17804951 -0.17337612 -0.15770155  0.66666667 -0.15753947]\n",
      " [-0.17804952 -0.17337612 -0.15770156  0.66666667 -0.15753946]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthijs/anaconda3/lib/python3.9/site-packages/torch/_tensor.py:643: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self.reciprocal() * other\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "######################################################################################\n",
    "# This Part includes Algorithm B.1 and B.2 from the paper. The assumptions made are: #\n",
    "# 1. g1 is bigger than 0, for all samples 2. we need to take a threshold to compare  #\n",
    "# constants in r_2.                                                                  #\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "from random import choice\n",
    "\n",
    "TH_POW = 8\n",
    "\n",
    "def exact_label_reconstruction(loss_vector_ratio):\n",
    "    if np.sum(loss_vector_ratio<0)>0: # The bigger than sign, I am not sure about\n",
    "        return np.argmin(loss_vector_ratio) # I am not sure about this either\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def find_disjoint_index_groups(arr: np.ndarray) -> dict:\n",
    "    unique_vals, counts = np.unique(arr, return_counts=True)\n",
    "    dup_vals = unique_vals[(counts>1)*(~np.isinf(unique_vals))*(~np.isnan(unique_vals))]\n",
    "    I = {}\n",
    "    for i, val in enumerate(dup_vals):\n",
    "        I[f\"m_{i}\"] = np.argwhere(arr==val).flatten()\n",
    "    return I\n",
    "\n",
    "#take batch 0 and epoch 0 \n",
    "def determine_g(GH, output_size=5):\n",
    "    G1 = GH[0]\n",
    "    G = np.zeros((output_size, G1.shape[0]))\n",
    "    r = np.zeros((output_size, G1.shape[0]))\n",
    "\n",
    "    for c in range(output_size):\n",
    "        G[c] = GH[c]\n",
    "        r[c] = np.round(G[c]/G1, TH_POW) # This threshold is to avoid numerical errors\n",
    "\n",
    "    r_2 = r[1]\n",
    "    exans = False\n",
    "    disjoint_index_groups = find_disjoint_index_groups(r_2)\n",
    "\n",
    "    if len(disjoint_index_groups)>0:\n",
    "        print(\"disjoint index group\", disjoint_index_groups)\n",
    "        exans = True\n",
    "\n",
    "    if exans:\n",
    "        reconstructable_samples = len(disjoint_index_groups)\n",
    "        ratio_vector = np.zeros((output_size, reconstructable_samples))\n",
    "        for c in range(output_size):\n",
    "            for m in range(reconstructable_samples):\n",
    "                j = choice(disjoint_index_groups[f\"m_{m}\"])\n",
    "                ratio_vector[c][m] = r[c][j]\n",
    "\n",
    "        g1 = np.zeros((reconstructable_samples))\n",
    "        g = np.zeros((reconstructable_samples, output_size))\n",
    "        for m in range(reconstructable_samples):\n",
    "            Ym = exact_label_reconstruction(ratio_vector[:, m])\n",
    "            delta_m = 1/ratio_vector[Ym, m]\n",
    "            g1[m] = 2 * delta_m/3\n",
    "            g[m] = ratio_vector[:, m] * g1[m]\n",
    "        return disjoint_index_groups, g, reconstructable_samples\n",
    "\n",
    "    else:\n",
    "        print(\"no exans\")\n",
    "        return None, None, None\n",
    "\n",
    "disjoint_index_groups, g, reconstructable_samples = determine_g(G_layers[1])\n",
    "print(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "#######################################################################################\n",
    "# This Part includes Algorithm B.3 from the paper. The implementation is not complete #\n",
    "# yet, because there are some gaps in the understanding of the paper.                 #\n",
    "#######################################################################################\n",
    "#######################################################################################\n",
    "\n",
    "def determine_activation_pattern(G, IH, g, M):\n",
    "    I_cur = IH\n",
    "    D = {}\n",
    "    for i in reversed(range(len(G)-1)):\n",
    "        D[f\"layer_{i}\"] = {}\n",
    "        for m in range(M):\n",
    "            j = choice(I_cur[f\"m_{m}\"])\n",
    "            D[f\"layer_{i}\"][f\"m_{m}\"] = np.diag(G[i][j][G[i][j]!=0]) # needs to be D[i][m] but for now, let's just do it for one sample\n",
    "            # # also how come we select a random j, whiy dont we use all?\n",
    "            # # and why only nonzero values? because this leads to inconsistent dimensions\n",
    "        # I_cur = find_disjoint_index_groups(?) How do we find the d\n",
    "    # there is no sensible way to solve the D from the binary equation, because here the weights would not have the same dimensions as D\n",
    "    return D\n",
    "D = determine_activation_pattern(G_layers, disjoint_index_groups, g, reconstructable_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
