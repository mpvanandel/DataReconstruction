{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import trange\n",
    "from tensorboardX import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import medmnist\n",
    "from medmnist import RetinaMNIST\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/matthijs/.medmnist/retinamnist.npz\n"
     ]
    }
   ],
   "source": [
    "num_samples = 8\n",
    "info = INFO[\"retinamnist\"]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=True, as_rgb=True)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=num_samples, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f98bd1aa4c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input, label = next(iter(train_loader))\n",
    "print(input[7].shape)\n",
    "plt.imshow(np.swapaxes(input[7],0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() takes 7 positional arguments but 9 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/matthijs/DataReconstruction/fcn_pytorch.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matthijs/DataReconstruction/fcn_pytorch.ipynb#W3sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m \u001b[39m# for epoch in trange(num_epochs):\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matthijs/DataReconstruction/fcn_pytorch.ipynb#W3sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m inputs, targets \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/matthijs/DataReconstruction/fcn_pytorch.ipynb#W3sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m epoch_loss, G_layer1, G_layer2 \u001b[39m=\u001b[39m train(model, train_loader, criterion, optimizer, \u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m, writer, num_batches, inputs, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matthijs/DataReconstruction/fcn_pytorch.ipynb#W3sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39m# print(np.max(G_layer1)) #[1]/G_layer2[0])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/matthijs/DataReconstruction/fcn_pytorch.ipynb#W3sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m gradients_layer1\u001b[39m.\u001b[39mappend(G_layer1)\n",
      "\u001b[0;31mTypeError\u001b[0m: train() takes 7 positional arguments but 9 were given"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((x.shape[0], x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def train(model, criterion, optimizer, device, writer, inputs, targets):\n",
    "    total_loss = []\n",
    "    global iteration\n",
    "\n",
    "    model.train()\n",
    "    g_layer1 = []\n",
    "    g_layer2 = []\n",
    "    # for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    #     if batch_idx > num_batches: # for now, let's only look at two batches\n",
    "    #         break\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs.to(device))\n",
    "\n",
    "    targets = torch.squeeze(targets, 1).long().to(device)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    total_loss.append(loss.item())\n",
    "    writer.add_scalar('train_loss_logs', loss.item(), iteration)\n",
    "    iteration += 1\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    g_layer1 = model.fc1.weight.grad\n",
    "    g_layer2 = model.fc2.weight.grad\n",
    "        # print(model.fc2.weight.grad[0])\n",
    "    #     if batch_idx==0:\n",
    "    #         G_layer1 = model.fc1.weight.grad\n",
    "    #         G_layer2 = model.fc2.weight.grad\n",
    "    #     else:\n",
    "    #         G_layer1 += model.fc1.weight.grad\n",
    "    #         G_layer2 += model.fc2.weight.grad\n",
    "\n",
    "    # G_layer1 /= num_batches\n",
    "    # G_layer2 /= num_batches\n",
    "    epoch_loss = sum(total_loss)/len(total_loss)\n",
    "    return epoch_loss, g_layer1, g_layer2\n",
    "\n",
    "\n",
    "# Define model and optimizer\n",
    "model = MyModel(3*28*28)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "iteration = 0\n",
    "num_epochs = 1\n",
    "num_batches = 5\n",
    "gradients_layer1 = []\n",
    "gradients_layer2 = []\n",
    "# for epoch in trange(num_epochs):\n",
    "inputs, targets = next(iter(train_loader))\n",
    "epoch_loss, G_layer1, G_layer2 = train(model, criterion, optimizer, \"cpu\", writer, inputs, targets)\n",
    "\n",
    "    # print(np.max(G_layer1)) #[1]/G_layer2[0])\n",
    "gradients_layer1.append(G_layer1)\n",
    "gradients_layer2.append(G_layer2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_values(arr: np.ndarray) -> np.ndarray:\n",
    "    unique_vals, counts = np.unique(arr, return_counts=True)\n",
    "    dup_vals = unique_vals[(counts>1)]#*(~np.isnan(unique_vals))]\n",
    "    idcs = np.argwhere(np.array([(val  in dup_vals) for val in arr]))\n",
    "    return idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no exans\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "\n",
    "def exact_label_reconstruction(loss_vector):\n",
    "    if np.sum(loss_vector<0)==1:\n",
    "        return np.argwhere(loss_vector<0)[0]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#take batch 0 and epoch 0 \n",
    "G1 = gradients_layer2[0][0][0,:]\n",
    "G = np.zeros((5, G1.shape[0]))\n",
    "r = np.zeros((5, G1.shape[0]))\n",
    "\n",
    "for c in range(5):\n",
    "    G[c] = gradients_layer2[0][0][c,:]\n",
    "    r[c] = G[c]/G1\n",
    "\n",
    "r_2 = r[1]\n",
    "\n",
    "indices = []\n",
    "exans = False\n",
    "for c in range(1, 5):\n",
    "    indices.append(find_duplicate_values(r[c]))\n",
    "    if len(indices[-1])>0:\n",
    "        print(\"disjoint index group\", indices[-1])\n",
    "        exans = True\n",
    "\n",
    "if exans:\n",
    "    for c in range(1, 5):\n",
    "        for m in range(num_samples):\n",
    "            j = choice(indices[c-1])\n",
    "            # print(r[c][j])\n",
    "            # print(r_2[j])\n",
    "            #Y_lab[m] = exact_label_reconstruction(gradients_layer2[0][0][:,j])\n",
    "\n",
    "\n",
    "    Y_lab = np.zeros(num_samples)\n",
    "    for m in range(num_samples):\n",
    "        continue\n",
    "else:\n",
    "    print(\"no exans\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
